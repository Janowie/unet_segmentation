{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net Brain Tumor Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'model' from 'C:\\\\Users\\\\krcma\\\\Desktop\\\\tf_segmentation\\\\unet_segmentation\\\\model.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.callbacks import Callback\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import SimpleITK as sitka\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "import time\n",
    "\n",
    "# Data augmentation\n",
    "import cv2\n",
    "from albumentations import (\n",
    "    Compose, HorizontalFlip, VerticalFlip, CLAHE, HueSaturationValue,\n",
    "    RandomBrightness, RandomContrast, RandomGamma,\n",
    "    ToFloat, ShiftScaleRotate, ElasticTransform, Rotate, RandomScale, GridDistortion, OpticalDistortion, OneOf\n",
    ")\n",
    "\n",
    "# Custom scripts\n",
    "import datagen\n",
    "import model as unet_model_script\n",
    "\n",
    "# Reload lib contents\n",
    "importlib.reload(datagen)\n",
    "importlib.reload(unet_model_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Hyperparemeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_HGG_patients = 239\n",
    "valid_HGG_patients = 20\n",
    "slices_from_patient = 15\n",
    "\n",
    "image_size = 240\n",
    "channels = 4\n",
    "learning_rate = 1e-4\n",
    "epochs = 25\n",
    "batch_size = 7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-Net model parameters\n",
    "\n",
    "Configuration dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = {\n",
    "    \"last_layer_activation\": \"sigmoid\",\n",
    "    \"dropout\": 0.05,\n",
    "    \"batch_norm\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_model_conf = {\n",
    "    \"optimizer\": keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "    \"loss\": \"binary_crossentropy\",\n",
    "    \"metrics\": [\"accuracy\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data with shape: (3585, 4, 240, 240) (3585, 1, 240, 240)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = datagen.get_dataset(slices_from_patient, \n",
    "                                        file_path='../dataset/', \n",
    "                                        mode='training', \n",
    "                                        glioma_type=['HGG'], \n",
    "                                        slices_w_tumor_only=100,\n",
    "                                        slices_w_less_brain=None,\n",
    "                                        image_size=image_size,\n",
    "                                        train_HGG_patients=train_HGG_patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation data with shape: (300, 4, 240, 240) (300, 1, 240, 240)\n"
     ]
    }
   ],
   "source": [
    "x_valid, y_valid = datagen.get_dataset(slices_from_patient, \n",
    "                                        file_path='../dataset/', \n",
    "                                        mode='validation', \n",
    "                                        glioma_type=['HGG'], \n",
    "                                        slices_w_tumor_only=False,\n",
    "                                        slices_w_less_brain=None,\n",
    "                                        image_size=240,\n",
    "                                        train_HGG_patients=valid_HGG_patients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUGMENTATIONS = Compose([\n",
    "    HorizontalFlip(p=0.5),\n",
    "    VerticalFlip(p=0.5),\n",
    "#     Rotate(limit=90, p=0.99),\n",
    "#     RandomGamma(gamma_limit=(80, 120), p=0.25),\n",
    "#     RandomScale(scale_limit=0.1, interpolation=cv2.INTER_NEAREST, p=0.25),\n",
    "#     ElasticTransform(alpha=1, p=0.5),\n",
    "#     OneOf([\n",
    "#         OpticalDistortion(p=0.3),\n",
    "#         GridDistortion(p=0.1),\n",
    "#     ], p=0.2),\n",
    "    OpticalDistortion(p=0.5),\n",
    "    GridDistortion(p=0.5),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NegativeLoss(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        pass\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        if logs.get('loss') < 0:\n",
    "            print(\"\\nEarly stopping for negative loss ({}) at batch {}.\".format(logs.get('loss'), batch))\n",
    "            self.model.stop_training = True\n",
    "\n",
    "callbacks = [\n",
    "    NegativeLoss(),\n",
    "    keras.callbacks.callbacks.TerminateOnNaN(),\n",
    "    keras.callbacks.callbacks.EarlyStopping(monitor='accuracy', \n",
    "                                            min_delta=0.0001, \n",
    "                                            patience=10, \n",
    "                                            verbose=1, \n",
    "                                            mode='auto', \n",
    "                                            baseline=None, \n",
    "                                            restore_best_weights=True),\n",
    "    keras.callbacks.callbacks.ReduceLROnPlateau(factor=0.1, \n",
    "                                                patience=5, \n",
    "                                                min_lr=0.00001, \n",
    "                                                verbose=1),\n",
    "#     keras.callbacks.TensorBoard(log_dir=\"../logs/{}\".format(time.time()))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training U-Net 1\n",
      "Epoch 1/25\n",
      "513/513 [==============================] - 279s 544ms/step - loss: 0.0956 - accuracy: 0.9887 - val_loss: 0.0570 - val_accuracy: 0.9902\n",
      "Epoch 2/25\n",
      "513/513 [==============================] - 261s 509ms/step - loss: 0.0605 - accuracy: 0.9874 - val_loss: 0.0459 - val_accuracy: 0.9890\n",
      "Epoch 3/25\n",
      "513/513 [==============================] - 269s 525ms/step - loss: 0.0429 - accuracy: 0.9889 - val_loss: 0.1283 - val_accuracy: 0.9861\n",
      "Epoch 4/25\n",
      "513/513 [==============================] - 317s 619ms/step - loss: 0.0360 - accuracy: 0.9894 - val_loss: 0.0331 - val_accuracy: 0.9908\n",
      "Epoch 5/25\n",
      "513/513 [==============================] - 310s 604ms/step - loss: 0.0309 - accuracy: 0.9901 - val_loss: 0.0306 - val_accuracy: 0.9900\n",
      "Epoch 6/25\n",
      "285/513 [===============>..............] - ETA: 2:18 - loss: 0.0281 - accuracy: 0.9906"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "for tumor_region in range(1, 2):\n",
    "    \n",
    "    print(\"Training U-Net {}\".format(tumor_region))\n",
    "    \n",
    "    # Get and compile model\n",
    "    models[tumor_region] = unet_model_script.UNet(channels, image_size, conf=conf)\n",
    "    models[tumor_region].compile(**training_model_conf)\n",
    "    \n",
    "    # Convert mask labels to binary\n",
    "    train_masks = datagen.convert_labels(y_train, tumor_region)\n",
    "    valid_masks = datagen.convert_labels(y_valid, tumor_region)\n",
    "    \n",
    "    # Init datagen w augmentation\n",
    "    train_gen = datagen.AugmentationDatagen(x_train, train_masks, batch_size, AUGMENTATIONS)\n",
    "    \n",
    "    # Start training\n",
    "    time_start = time.time()\n",
    "    models[\"hist_{}\".format(tumor_region)] = models[tumor_region].fit(train_gen, \n",
    "                                                                      validation_data=(x_valid, valid_masks), \n",
    "                                                                      epochs=epochs, \n",
    "                                                                      shuffle=True, \n",
    "                                                                      callbacks=callbacks)\n",
    "    print(\"Training time: {}\".format(time.time()-time_start))\n",
    "    \n",
    "#     model.save(\"../models/ensemble_{}.h5\".format(time.time(), tumor_region))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tumor_region = 1\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(models[\"hist_{}\".format(tumor_region)].history['accuracy'])\n",
    "plt.plot(models[\"hist_{}\".format(tumor_region)].history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(models[\"hist_{}\".format(tumor_region)].history['loss'])\n",
    "plt.plot(models[\"hist_{}\".format(tumor_region)].history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_valid, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
